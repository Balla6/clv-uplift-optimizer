{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9fd84d9-64b0-4bfc-b648-53911a263279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CHECKLIST\n",
      "\n",
      "[models]\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\models\\preprocess.joblib\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\models\\rf_treated.joblib\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\models\\rf_control.joblib\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\models\\meta.json\n",
      "\n",
      "[tools]\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\tools\\score_contacts.py\n",
      "\n",
      "[processed csvs]\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\hillstrom_uplift_curve.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\hillstrom_uplift_deciles.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\policy_curve_email.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\policy_contact_list.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\policy_sensitivity.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\hillstrom_uplift_scores_test.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\nb_scored_test.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\cli_sanity_contacts_test.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\required_features_schema.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\scored_contacts.csv\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\scored_contacts_with_flag.csv\n",
      "\n",
      "[figures (optional)]\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\figs\\policy_sensitivity_heatmap.png \n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\figs\\campaign_economics.png \n",
      "\n",
      "[packs / reports (optional)]\n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\policy_pack.xlsx \n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\reports\\*.html \n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\contact_pack_*.xlsx \n",
      "  ✓ C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\contact_pack_*.md \n",
      "\n",
      "# PARITY (TEST-ONLY)\n",
      "Rows in common: 3724 / 16000\n",
      "Pearson corr: 1.000000  |  Top-1000 overlap: 1.000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, json, os, glob\n",
    "\n",
    "# Project roots\n",
    "PROJ = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROC = PROJ / \"data\" / \"processed\"\n",
    "RAW  = PROJ / \"data\" / \"raw\"\n",
    "MODELS = PROJ / \"models\"\n",
    "TOOLS  = PROJ / \"tools\"\n",
    "FIGS   = PROC / \"figs\"\n",
    "\n",
    "def exists(p): \n",
    "    p = Path(p); \n",
    "    return p.exists() and (p.stat().st_size > 0)\n",
    "\n",
    "# --- Required files checklist ---\n",
    "required = {\n",
    "    \"models\": [\n",
    "        MODELS/\"preprocess.joblib\",\n",
    "        MODELS/\"rf_treated.joblib\",\n",
    "        MODELS/\"rf_control.joblib\",\n",
    "        MODELS/\"meta.json\",\n",
    "    ],\n",
    "    \"tools\": [\n",
    "        TOOLS/\"score_contacts.py\",\n",
    "    ],\n",
    "    \"processed csvs\": [\n",
    "        PROC/\"hillstrom_uplift_curve.csv\",\n",
    "        PROC/\"hillstrom_uplift_deciles.csv\",\n",
    "        PROC/\"policy_curve_email.csv\",\n",
    "        PROC/\"policy_contact_list.csv\",\n",
    "        PROC/\"policy_sensitivity.csv\",\n",
    "        PROC/\"hillstrom_uplift_scores_test.csv\",\n",
    "        PROC/\"nb_scored_test.csv\",                # from notebook scoring of test-only\n",
    "        PROC/\"cli_sanity_contacts_test.csv\",      # from CLI scoring of test-only\n",
    "        PROC/\"required_features_schema.csv\",\n",
    "        PROC/\"scored_contacts.csv\",               # your new “real” scoring\n",
    "        PROC/\"scored_contacts_with_flag.csv\",     # same with should_contact flag\n",
    "    ],\n",
    "}\n",
    "\n",
    "optional_globs = {\n",
    "    \"figures (optional)\": [\n",
    "        str(FIGS/\"policy_sensitivity_heatmap.png\"),\n",
    "        str(FIGS/\"campaign_economics.png\"),\n",
    "    ],\n",
    "    \"packs / reports (optional)\": [\n",
    "        str(PROC/\"policy_pack.xlsx\"),\n",
    "        str(PROC/\"reports/*.html\"),\n",
    "        str(PROC/\"contact_pack_*.xlsx\"),\n",
    "        str(PROC/\"contact_pack_*.md\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"# CHECKLIST\")\n",
    "missing = False\n",
    "for bucket, files in required.items():\n",
    "    print(f\"\\n[{bucket}]\")\n",
    "    for f in files:\n",
    "        ok = exists(f)\n",
    "        print(\"  ✓\" if ok else \"  ✗\", f)\n",
    "        missing |= (not ok)\n",
    "\n",
    "for bucket, patterns in optional_globs.items():\n",
    "    print(f\"\\n[{bucket}]\")\n",
    "    for pat in patterns:\n",
    "        matches = [m for m in glob.glob(pat) if exists(m)]\n",
    "        ok = len(matches) > 0\n",
    "        print(\"  ✓\" if ok else \"  –\", pat, (\"\" if ok else \"(none found)\"))\n",
    "\n",
    "# --- Parity sanity: notebook vs CLI on TEST-ONLY ---\n",
    "print(\"\\n# PARITY (TEST-ONLY)\")\n",
    "try:\n",
    "    nb  = pd.read_csv(PROC/\"nb_scored_test.csv\")[[\"row_id\",\"uplift_hat\"]]\n",
    "    cli = pd.read_csv(PROC/\"cli_sanity_contacts_test.csv\")[[\"row_id\",\"uplift_hat\"]].rename(columns={\"uplift_hat\":\"uplift_cli\"})\n",
    "    cmp = nb.merge(cli, on=\"row_id\", how=\"inner\")\n",
    "    corr = cmp[[\"uplift_hat\",\"uplift_cli\"]].corr().iloc[0,1]\n",
    "    k = 1000\n",
    "    nb_top  = set(cmp.sort_values(\"uplift_hat\", ascending=False).head(k)[\"row_id\"])\n",
    "    cli_top = set(cmp.sort_values(\"uplift_cli\",  ascending=False).head(k)[\"row_id\"])\n",
    "    overlap = len(nb_top & cli_top)/k\n",
    "    print(f\"Rows in common: {len(cmp)} / {len(nb)}\")\n",
    "    print(f\"Pearson corr: {corr:.6f}  |  Top-{k} overlap: {overlap:.3f}\")\n",
    "except Exception as e:\n",
    "    print(\"Parity check skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be287a24-0555-4726-9dd8-7dcfcbfae0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in common: 16000 / 16000\n",
      "Pearson corr:   1.0\n",
      "Top-1000 overlap: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, json, joblib\n",
    "\n",
    "PROJ = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROC = PROJ / \"data\" / \"processed\"\n",
    "\n",
    "nb  = pd.read_csv(PROC / \"nb_scored_test.csv\")[[\"row_id\",\"uplift_hat\"]]\n",
    "cli = pd.read_csv(PROC / \"cli_all_scored_test.csv\")[[\"row_id\",\"uplift_hat\"]].rename(columns={\"uplift_hat\":\"uplift_cli\"})\n",
    "\n",
    "cmp = nb.merge(cli, on=\"row_id\", how=\"inner\")\n",
    "print(\"Rows in common:\", len(cmp), \"/\", len(nb))\n",
    "print(\"Pearson corr:  \", round(cmp[\"uplift_hat\"].corr(cmp[\"uplift_cli\"]), 6))\n",
    "\n",
    "k = 1000\n",
    "nb_top  = set(cmp.sort_values(\"uplift_hat\", ascending=False).head(k)[\"row_id\"])\n",
    "cli_top = set(cmp.sort_values(\"uplift_cli\",  ascending=False).head(k)[\"row_id\"])\n",
    "print(f\"Top-{k} overlap:\", round(len(nb_top & cli_top) / k, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f7f21-88aa-4156-9698-1a12c4686929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Jupyter)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
