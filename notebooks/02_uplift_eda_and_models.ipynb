{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b536291a",
   "metadata": {},
   "source": [
    "# Uplift EDA & Models (T-/X-learner, Trees)\n",
    "\n",
    "This is a starter notebook. We'll fill it in Step 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf08285-63c1-44d2-8c8e-6601279878a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\raw\\hillstrom.csv | Source: sklift.fetch_hillstrom\n",
      "Shape: (64000, 10)\n",
      "Treatment counts: {'Womens E-Mail': 21387, 'Mens E-Mail': 21307, 'No E-Mail': 21306}\n",
      "Mean spend by treatment: {'Mens E-Mail': 1.423, 'No E-Mail': 0.653, 'Womens E-Mail': 1.077}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history_segment</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>newbie</th>\n",
       "      <th>channel</th>\n",
       "      <th>spend</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2) $100 - $200</td>\n",
       "      <td>142.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Womens E-Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3) $200 - $350</td>\n",
       "      <td>329.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No E-Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2) $100 - $200</td>\n",
       "      <td>180.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Womens E-Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>5) $500 - $750</td>\n",
       "      <td>675.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mens E-Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1) $0 - $100</td>\n",
       "      <td>45.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>0</td>\n",
       "      <td>Web</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Womens E-Mail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recency history_segment  history  mens  womens   zip_code  newbie channel  \\\n",
       "0       10  2) $100 - $200   142.44     1       0  Surburban       0   Phone   \n",
       "1        6  3) $200 - $350   329.08     1       1      Rural       1     Web   \n",
       "2        7  2) $100 - $200   180.65     0       1  Surburban       1     Web   \n",
       "3        9  5) $500 - $750   675.83     1       0      Rural       1     Web   \n",
       "4        2    1) $0 - $100    45.34     1       0      Urban       0     Web   \n",
       "\n",
       "   spend      treatment  \n",
       "0    0.0  Womens E-Mail  \n",
       "1    0.0      No E-Mail  \n",
       "2    0.0  Womens E-Mail  \n",
       "3    0.0    Mens E-Mail  \n",
       "4    0.0  Womens E-Mail  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3a — Load Hillstrom reliably and save to data/raw/hillstrom.csv\n",
    "from pathlib import Path\n",
    "import sys, subprocess, importlib.util as iutil\n",
    "import pandas as pd\n",
    "\n",
    "PROJ = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "RAW = PROJ / \"data\" / \"raw\"\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ensure(pkg, pip_name=None):\n",
    "    if iutil.find_spec(pkg) is None:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pip_name or pkg])\n",
    "\n",
    "ensure(\"sklift\", \"scikit-uplift\")\n",
    "\n",
    "from sklift.datasets import fetch_hillstrom\n",
    "\n",
    "try:\n",
    "    # Correct signature per scikit-uplift docs\n",
    "    X, y, t = fetch_hillstrom(target_col=\"spend\", return_X_y_t=True)\n",
    "    hill = pd.concat(\n",
    "        [pd.DataFrame(X).reset_index(drop=True),\n",
    "         pd.Series(y, name=\"spend\").reset_index(drop=True),\n",
    "         pd.Series(t, name=\"treatment\").reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "    source = \"sklift.fetch_hillstrom\"\n",
    "except Exception as e:\n",
    "    # Fallback: read the dataset from scikit-uplift’s S3 mirror (per docs)\n",
    "    url = \"https://hillstorm1.s3.us-east-2.amazonaws.com/hillstorm_no_indices.csv.gz\"\n",
    "    hill = pd.read_csv(url, compression=\"gzip\")\n",
    "    if \"treatment\" not in hill.columns and \"segment\" in hill.columns:\n",
    "        hill[\"treatment\"] = (hill[\"segment\"].astype(str) != \"No E-Mail\").astype(int)\n",
    "    if \"spend\" not in hill.columns:\n",
    "        # fallback to visit/conversion if needed\n",
    "        if \"conversion\" in hill.columns:\n",
    "            hill[\"spend\"] = pd.to_numeric(hill[\"conversion\"], errors=\"coerce\").fillna(0.0)\n",
    "        elif \"visit\" in hill.columns:\n",
    "            hill[\"spend\"] = pd.to_numeric(hill[\"visit\"], errors=\"coerce\").fillna(0.0)\n",
    "        else:\n",
    "            raise\n",
    "    source = \"S3 direct\"\n",
    "\n",
    "out = RAW / \"hillstrom.csv\"\n",
    "hill.to_csv(out, index=False)\n",
    "\n",
    "print(\"Saved:\", out, \"| Source:\", source)\n",
    "print(\"Shape:\", hill.shape)\n",
    "print(\"Treatment counts:\", hill[\"treatment\"].value_counts().to_dict())\n",
    "print(\"Mean spend by treatment:\", hill.groupby(\"treatment\")[\"spend\"].mean().round(3).to_dict())\n",
    "hill.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af05377-0dd2-4f34-a379-085851b0aacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history_segment</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>newbie</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26859</th>\n",
       "      <td>1</td>\n",
       "      <td>1) $0 - $100</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44631</th>\n",
       "      <td>1</td>\n",
       "      <td>4) $350 - $500</td>\n",
       "      <td>424.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>Multichannel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165</th>\n",
       "      <td>1</td>\n",
       "      <td>1) $0 - $100</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>0</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62255</th>\n",
       "      <td>1</td>\n",
       "      <td>5) $500 - $750</td>\n",
       "      <td>669.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43677</th>\n",
       "      <td>5</td>\n",
       "      <td>2) $100 - $200</td>\n",
       "      <td>134.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recency history_segment  history  mens  womens   zip_code  newbie  \\\n",
       "26859        1    1) $0 - $100    29.99     1       0      Urban       1   \n",
       "44631        1  4) $350 - $500   424.10     0       1      Urban       1   \n",
       "29165        1    1) $0 - $100    29.99     0       1      Urban       0   \n",
       "62255        1  5) $500 - $750   669.66     0       1  Surburban       1   \n",
       "43677        5  2) $100 - $200   134.29     1       0  Surburban       0   \n",
       "\n",
       "            channel  \n",
       "26859           Web  \n",
       "44631  Multichannel  \n",
       "29165           Web  \n",
       "62255           Web  \n",
       "43677         Phone  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROJ = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "RAW  = PROJ / \"data\" / \"raw\"\n",
    "PROC = PROJ / \"data\" / \"processed\"\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hill = pd.read_csv(RAW / \"hillstrom.csv\")\n",
    "\n",
    "# Binary treatment: 1 if emailed (Mens/Womens), 0 if No E-Mail\n",
    "treat = (hill[\"treatment\"].astype(str) != \"No E-Mail\").astype(int)\n",
    "\n",
    "# Target = spend (numeric)\n",
    "y = pd.to_numeric(hill[\"spend\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# Features: drop current-treatment label & any explicit “segment”\n",
    "X = hill.drop(columns=[\"spend\",\"treatment\",\"segment\"], errors=\"ignore\")\n",
    "\n",
    "# Train/test split (stratify by treatment keeps the randomization ratio)\n",
    "X_tr, X_te, y_tr, y_te, t_tr, t_te = train_test_split(\n",
    "    X, y, treat, test_size=0.25, random_state=42, stratify=treat\n",
    ")\n",
    "\n",
    "X_tr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df5138ac-9892-4cea-854d-6887b536215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1_hat</th>\n",
       "      <th>y0_hat</th>\n",
       "      <th>uplift_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6636</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>-0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y1_hat  y0_hat  uplift_hat\n",
       "0  3.6636  0.0000      3.6636\n",
       "1  0.0000  0.9792     -0.9792\n",
       "2  0.0000  0.0000      0.0000\n",
       "3  0.0000  0.0000      0.0000\n",
       "4  0.0000  0.0000      0.0000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Separate numeric vs categorical columns\n",
    "num_cols = X_tr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X_tr.columns if c not in num_cols]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", \"passthrough\", num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "])\n",
    "\n",
    "# Fit encoder on train only, then transform\n",
    "pre.fit(X_tr)\n",
    "A_tr = pre.transform(X_tr)\n",
    "A_te = pre.transform(X_te)\n",
    "\n",
    "# Two models: one for treated, one for control\n",
    "reg_t = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "reg_c = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "\n",
    "reg_t.fit(A_tr[t_tr==1], y_tr[t_tr==1])\n",
    "reg_c.fit(A_tr[t_tr==0], y_tr[t_tr==0])\n",
    "\n",
    "# Predict potential outcomes on test\n",
    "y1_hat = reg_t.predict(A_te)   # predicted spend if treated\n",
    "y0_hat = reg_c.predict(A_te)   # predicted spend if control\n",
    "uplift_hat = y1_hat - y0_hat   # predicted incremental spend\n",
    "pd.DataFrame({\"y1_hat\": y1_hat, \"y0_hat\": y0_hat, \"uplift_hat\": uplift_hat}).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e629cf4-0a90-469c-baa7-f44602b203a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best policy size ≈ top 99.09% of customers (n=15855)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>cum_gain</th>\n",
       "      <th>cum_gain_per_customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>1671.495720</td>\n",
       "      <td>1.044685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3200</td>\n",
       "      <td>2234.158113</td>\n",
       "      <td>0.698174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4800</td>\n",
       "      <td>5416.774770</td>\n",
       "      <td>1.128495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6400</td>\n",
       "      <td>5936.907457</td>\n",
       "      <td>0.927642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8000</td>\n",
       "      <td>6924.475859</td>\n",
       "      <td>0.865559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9600</td>\n",
       "      <td>5353.296828</td>\n",
       "      <td>0.557635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11200</td>\n",
       "      <td>7187.110750</td>\n",
       "      <td>0.641706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12800</td>\n",
       "      <td>8058.977127</td>\n",
       "      <td>0.629608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14400</td>\n",
       "      <td>8436.671680</td>\n",
       "      <td>0.585880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16000</td>\n",
       "      <td>10191.235193</td>\n",
       "      <td>0.636952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n      cum_gain  cum_gain_per_customer\n",
       "0   1600   1671.495720               1.044685\n",
       "1   3200   2234.158113               0.698174\n",
       "2   4800   5416.774770               1.128495\n",
       "3   6400   5936.907457               0.927642\n",
       "4   8000   6924.475859               0.865559\n",
       "5   9600   5353.296828               0.557635\n",
       "6  11200   7187.110750               0.641706\n",
       "7  12800   8058.977127               0.629608\n",
       "8  14400   8436.671680               0.585880\n",
       "9  16000  10191.235193               0.636952"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Propensity of treatment in training (randomized design)\n",
    "p = float(t_tr.mean())\n",
    "\n",
    "# Inverse propensity weighting contribution for each test row\n",
    "w = y_te.to_numpy() * ( (t_te.to_numpy()/p) - ((1 - t_te.to_numpy())/(1 - p)) )\n",
    "\n",
    "# Rank by predicted uplift desc\n",
    "order = np.argsort(-uplift_hat)\n",
    "w_sorted = w[order]\n",
    "\n",
    "# Cumulative incremental value\n",
    "cum_gain = np.cumsum(w_sorted)\n",
    "n = np.arange(1, len(cum_gain)+1)\n",
    "gain_df = pd.DataFrame({\"n\": n, \"cum_gain\": cum_gain, \"cum_gain_per_customer\": cum_gain / n})\n",
    "\n",
    "# Deciles summary\n",
    "k = (np.linspace(0.1, 1.0, 10) * len(gain_df)).astype(int)\n",
    "deciles = gain_df.iloc[k-1][[\"n\",\"cum_gain\",\"cum_gain_per_customer\"]].reset_index(drop=True)\n",
    "\n",
    "best_idx = int(cum_gain.argmax()) + 1\n",
    "best_pct = round(100 * best_idx / len(gain_df), 2)\n",
    "\n",
    "print(f\"Best policy size ≈ top {best_pct}% of customers (n={best_idx})\")\n",
    "deciles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e26fa28e-2105-4400-8efb-84a035eb4a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\hillstrom_uplift_scores_test.csv\n",
      "Saved: C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\hillstrom_uplift_curve.csv\n",
      "Saved: C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\hillstrom_uplift_deciles.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>uplift_hat</th>\n",
       "      <th>y_actual</th>\n",
       "      <th>treated</th>\n",
       "      <th>ipw_contrib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11786</td>\n",
       "      <td>267.869600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13574</td>\n",
       "      <td>235.279467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8911</td>\n",
       "      <td>164.670000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9527</td>\n",
       "      <td>146.373333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10755</td>\n",
       "      <td>136.221167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10271</td>\n",
       "      <td>122.005300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3177</td>\n",
       "      <td>120.406233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7190</td>\n",
       "      <td>116.433333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9130</td>\n",
       "      <td>114.025333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11706</td>\n",
       "      <td>105.179967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  uplift_hat  y_actual  treated  ipw_contrib\n",
       "0   11786  267.869600       0.0        0         -0.0\n",
       "1   13574  235.279467       0.0        1          0.0\n",
       "2    8911  164.670000       0.0        1          0.0\n",
       "3    9527  146.373333       0.0        1          0.0\n",
       "4   10755  136.221167       0.0        1          0.0\n",
       "5   10271  122.005300       0.0        1          0.0\n",
       "6    3177  120.406233       0.0        1          0.0\n",
       "7    7190  116.433333       0.0        0         -0.0\n",
       "8    9130  114.025333       0.0        1          0.0\n",
       "9   11706  105.179967       0.0        1          0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save per-customer scores on the test set\n",
    "scores = pd.DataFrame({\n",
    "    \"row_id\": X_te.reset_index(drop=True).index,\n",
    "    \"uplift_hat\": uplift_hat,\n",
    "    \"y_actual\": y_te.to_numpy(),\n",
    "    \"treated\": t_te.to_numpy(),\n",
    "    \"ipw_contrib\": w,\n",
    "})\n",
    "scores_sorted = scores.iloc[order].reset_index(drop=True)\n",
    "\n",
    "scores_sorted.to_csv(PROC / \"hillstrom_uplift_scores_test.csv\", index=False)\n",
    "gain_df.to_csv(PROC / \"hillstrom_uplift_curve.csv\", index=False)\n",
    "deciles.to_csv(PROC / \"hillstrom_uplift_deciles.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", PROC / \"hillstrom_uplift_scores_test.csv\")\n",
    "print(\"Saved:\", PROC / \"hillstrom_uplift_curve.csv\")\n",
    "print(\"Saved:\", PROC / \"hillstrom_uplift_deciles.csv\")\n",
    "scores_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b822be8-3561-4229-b38d-d2f7d253cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\models\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJ = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "MODELD = PROJ / \"models\"\n",
    "MODELD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Recreate the feature lists exactly as you trained\n",
    "cat_cols = X_tr.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "num_cols = X_tr.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "feature_cols = list(X_tr.columns)\n",
    "\n",
    "joblib.dump(pre,   MODELD / \"preprocess.joblib\")\n",
    "joblib.dump(reg_t, MODELD / \"rf_treated.joblib\")\n",
    "joblib.dump(reg_c, MODELD / \"rf_control.joblib\")\n",
    "\n",
    "meta = {\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"num_cols\": num_cols,\n",
    "    \"target\": \"spend\",\n",
    "    \"treatment_col\": \"treatment\",\n",
    "    \"id_fallback\": \"row_id\"  # will be created at score-time if missing\n",
    "}\n",
    "(MODELD / \"meta.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved to:\", MODELD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44cb01e2-4a0c-468a-8139-ba116aba930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>uplift_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.406867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.312567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  uplift_hat\n",
       "0       0    0.000000\n",
       "1       1   -0.406867\n",
       "2       2    7.312567\n",
       "3       3    7.493800\n",
       "4       4    0.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, joblib, pandas as pd\n",
    "\n",
    "PROJ   = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "RAW    = PROJ / \"data\" / \"raw\"\n",
    "PROC   = PROJ / \"data\" / \"processed\"\n",
    "MODELS = PROJ / \"models\"\n",
    "\n",
    "# Use the test file you wrote earlier\n",
    "df = pd.read_csv(RAW / \"hillstrom_test_only.csv\")  # 16,000 rows\n",
    "\n",
    "# Load the artifacts you saved in step 02\n",
    "enc   = joblib.load(MODELS / \"preprocess.joblib\")\n",
    "reg_t = joblib.load(MODELS / \"rf_treated.joblib\")\n",
    "reg_c = joblib.load(MODELS / \"rf_control.joblib\")\n",
    "meta  = json.load(open(MODELS / \"meta.json\"))\n",
    "\n",
    "# Use exact feature order/dtypes\n",
    "feat_cols = meta[\"feature_cols\"]\n",
    "X = df[feat_cols].copy()\n",
    "for c in meta[\"cat_cols\"]:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype(str)\n",
    "\n",
    "A  = enc.transform(X)\n",
    "y1 = reg_t.predict(A)\n",
    "y0 = reg_c.predict(A)\n",
    "\n",
    "uplift_hat = y1 - y0\n",
    "nb_scored = pd.DataFrame({\n",
    "    \"row_id\": df.get(\"row_id\", pd.RangeIndex(len(df))),\n",
    "    \"uplift_hat\": uplift_hat\n",
    "})\n",
    "nb_scored.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c9647d7-803b-4bc5-befb-7139c01d6fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\tools\\score_contacts.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "code = r\"\"\"\n",
    "import argparse, json, joblib, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_models(model_dir: Path):\n",
    "    pre = joblib.load(model_dir / \"preprocess.joblib\")\n",
    "    reg_t = joblib.load(model_dir / \"rf_treated.joblib\")\n",
    "    reg_c = joblib.load(model_dir / \"rf_control.joblib\")\n",
    "    meta = json.loads((model_dir / \"meta.json\").read_text(encoding=\"utf-8\"))\n",
    "    return pre, reg_t, reg_c, meta\n",
    "\n",
    "def prepare_features(df: pd.DataFrame, meta: dict):\n",
    "    # ensure feature columns exist\n",
    "    for c in meta[\"feature_cols\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "    X = df[meta[\"feature_cols\"]].copy()\n",
    "    # keep types friendly\n",
    "    for c in X.columns:\n",
    "        if X[c].dtype == \"object\":\n",
    "            X[c] = X[c].astype(\"string\")\n",
    "    return X\n",
    "\n",
    "def score(input_csv, output_csv, model_dir, margin, cost, policy, topn=None, id_col=None):\n",
    "    model_dir = Path(model_dir)\n",
    "    pre, reg_t, reg_c, meta = load_models(model_dir)\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "    # Choose an ID column or create one\n",
    "    if id_col and id_col in df.columns:\n",
    "        ids = df[id_col].copy()\n",
    "    elif meta.get(\"id_fallback\") in df.columns:\n",
    "        ids = df[meta[\"id_fallback\"]].copy()\n",
    "    else:\n",
    "        ids = pd.Series(np.arange(len(df)), name=meta.get(\"id_fallback\",\"row_id\"))\n",
    "        df[ids.name] = ids\n",
    "\n",
    "    X = prepare_features(df, meta)\n",
    "    A = pre.transform(X)\n",
    "\n",
    "    y1_hat = reg_t.predict(A)\n",
    "    y0_hat = reg_c.predict(A)\n",
    "    uplift = y1_hat - y0_hat\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"row_id\": ids.values,\n",
    "        \"y1_hat\": y1_hat,\n",
    "        \"y0_hat\": y0_hat,\n",
    "        \"uplift_hat\": uplift\n",
    "    }).sort_values(\"uplift_hat\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    out[\"exp_incremental_revenue\"] = out[\"uplift_hat\"]\n",
    "    out[\"exp_profit_per_contact\"]  = margin*out[\"uplift_hat\"] - cost\n",
    "\n",
    "    # decide contacts\n",
    "    if policy == \"pos\":\n",
    "        chosen = out.loc[out[\"exp_profit_per_contact\"] > 0].copy()\n",
    "    elif policy == \"bestN\":\n",
    "        # maximize expected profit curve\n",
    "        cg = out[\"uplift_hat\"].cumsum()\n",
    "        n  = np.arange(1, len(out)+1)\n",
    "        profit_curve = margin*cg - cost*n\n",
    "        best_n = int(np.argmax(profit_curve) + 1)\n",
    "        if topn is not None:\n",
    "            best_n = int(topn)\n",
    "        chosen = out.head(best_n).copy()\n",
    "    else:\n",
    "        raise ValueError(\"policy must be 'pos' or 'bestN'\")\n",
    "\n",
    "    chosen[\"rank\"] = np.arange(1, len(chosen)+1)\n",
    "    cols = [\"row_id\",\"rank\",\"uplift_hat\",\"y1_hat\",\"y0_hat\",\"exp_incremental_revenue\",\"exp_profit_per_contact\"]\n",
    "    chosen[cols].to_csv(output_csv, index=False)\n",
    "\n",
    "    total_rev  = float(chosen[\"exp_incremental_revenue\"].sum())\n",
    "    total_cost = float(cost*len(chosen))\n",
    "    total_prof = float(margin*total_rev - total_cost)\n",
    "\n",
    "    print(f\"Contacts: {len(chosen)}  |  Expected revenue: {total_rev:,.2f}  |  Cost: {total_cost:,.2f}  |  Profit: {total_prof:,.2f}\")\n",
    "    print(\"Saved:\", output_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser(description=\"Score uplift and produce a contact list.\")\n",
    "    p.add_argument(\"--in\", dest=\"input_csv\",  required=True)\n",
    "    p.add_argument(\"--out\", dest=\"output_csv\", required=True)\n",
    "    p.add_argument(\"--models\", default=\"models\")\n",
    "    p.add_argument(\"--margin\", type=float, default=0.30)\n",
    "    p.add_argument(\"--cost\",   type=float, default=0.05)\n",
    "    p.add_argument(\"--policy\", choices=[\"pos\",\"bestN\"], default=\"pos\")\n",
    "    p.add_argument(\"--topn\", type=int, default=None, help=\"optional, only for policy=bestN\")\n",
    "    p.add_argument(\"--id_col\", default=None)\n",
    "    args = p.parse_args()\n",
    "    score(args.input_csv, args.output_csv, args.models, args.margin, args.cost, args.policy, args.topn, args.id_col)\n",
    "\"\"\"\n",
    "proj = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "tools = proj / \"tools\"\n",
    "tools.mkdir(parents=True, exist_ok=True)\n",
    "(target := tools / \"score_contacts.py\").write_text(code, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78e3817f-5c2f-4676-8708-74fba0d4209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\balla\\Downloads\\clv-uplift-optimizer-starter\\clv-uplift-optimizer\\data\\processed\\nb_scored_test.csv | rows: 16000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PROJ = Path.cwd().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PROC = PROJ / \"data\" / \"processed\"\n",
    "\n",
    "nb_out = PROC / \"nb_scored_test.csv\"\n",
    "nb_scored.to_csv(nb_out, index=False)\n",
    "print(\"Saved:\", nb_out, \"| rows:\", len(nb_scored))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f01c9c-3456-4e06-bb33-f3774dfaedf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
